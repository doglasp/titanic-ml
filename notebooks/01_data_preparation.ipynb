{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf205b0b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "741823e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, platform, random, numpy as np, pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1801798",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6b40112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.11.14\n"
     ]
    }
   ],
   "source": [
    "RAW_DIR   = \"../data\"\n",
    "CLEAN_DIR = \"../data/clean\"\n",
    "os.makedirs(CLEAN_DIR, exist_ok=True)\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "print(\"Python:\", platform.python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecad8d9",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edf59eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (891, 12)\n",
      "Test shape : (418, 11)\n"
     ]
    }
   ],
   "source": [
    "train_csv = os.path.join(RAW_DIR, \"train.csv\")\n",
    "test_csv  = os.path.join(RAW_DIR, \"test.csv\")   # se existir\n",
    "\n",
    "df_train = pd.read_csv(train_csv)\n",
    "df_test  = pd.read_csv(test_csv) if os.path.exists(test_csv) else None\n",
    "\n",
    "print(\"Train shape:\", df_train.shape)\n",
    "if df_test is not None: print(\"Test shape :\", df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77af2d54",
   "metadata": {},
   "source": [
    "## Basic quality report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9ce687d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== train dtypes ==\n",
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n",
      "\n",
      "== train missing values ==\n",
      "             n_missing        pct\n",
      "Cabin              687  77.104377\n",
      "Age                177  19.865320\n",
      "Embarked             2   0.224467\n",
      "PassengerId          0   0.000000\n",
      "Name                 0   0.000000\n",
      "Pclass               0   0.000000\n",
      "Survived             0   0.000000\n",
      "Sex                  0   0.000000\n",
      "Parch                0   0.000000\n",
      "SibSp                0   0.000000\n",
      "Fare                 0   0.000000\n",
      "Ticket               0   0.000000\n",
      "\n",
      "== train categorical cardinality ==\n",
      "Name        891\n",
      "Ticket      681\n",
      "Cabin       147\n",
      "Embarked      3\n",
      "Sex           2\n",
      "dtype: int64\n",
      "\n",
      "== test dtypes ==\n",
      "PassengerId      int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n",
      "\n",
      "== test missing values ==\n",
      "             n_missing        pct\n",
      "Cabin              327  78.229665\n",
      "Age                 86  20.574163\n",
      "Fare                 1   0.239234\n",
      "Name                 0   0.000000\n",
      "Pclass               0   0.000000\n",
      "PassengerId          0   0.000000\n",
      "Sex                  0   0.000000\n",
      "Parch                0   0.000000\n",
      "SibSp                0   0.000000\n",
      "Ticket               0   0.000000\n",
      "Embarked             0   0.000000\n",
      "\n",
      "== test categorical cardinality ==\n",
      "Name        418\n",
      "Ticket      363\n",
      "Cabin        76\n",
      "Embarked      3\n",
      "Sex           2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def quality_report(df: pd.DataFrame, label=\"df\"):\n",
    "    print(f\"\\n== {label} dtypes ==\")\n",
    "    print(df.dtypes)\n",
    "    miss = df.isna().sum().sort_values(ascending=False)\n",
    "    print(f\"\\n== {label} missing values ==\")\n",
    "    print(pd.DataFrame({\"n_missing\": miss, \"pct\": (miss/len(df))*100}).head(20))\n",
    "    print(f\"\\n== {label} categorical cardinality ==\")\n",
    "    cat_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "    card = {c: df[c].nunique(dropna=True) for c in cat_cols}\n",
    "    print(pd.Series(card).sort_values(ascending=False).head(20))\n",
    "\n",
    "quality_report(df_train, \"train\")\n",
    "if df_test is not None:\n",
    "    quality_report(df_test, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83158ad6",
   "metadata": {},
   "source": [
    "## Schema & presence checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e83a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_train_schema(df: pd.DataFrame, target: str) -> None:\n",
    "    assert target in df.columns, f\"Missing target: {target}\"\n",
    "    # columns your engineer_features needs:\n",
    "    required_for_eng = {\"SibSp\", \"Parch\"}  # add others if used inside engineer_features\n",
    "    miss = [c for c in required_for_eng if c not in df.columns]\n",
    "    if miss:\n",
    "        raise ValueError(f\"Missing columns needed for feature engineering: {miss}\")\n",
    "    # optional soft checks\n",
    "    num_hint = [\"Pclass\",\"Age\",\"SibSp\",\"Parch\",\"Fare\"]\n",
    "    cat_hint = [\"Sex\",\"Embarked\"]\n",
    "    warn = []\n",
    "    for c in num_hint:\n",
    "        if c in df and not pd.api.types.is_numeric_dtype(df[c]):\n",
    "            warn.append(f\"{c} not numeric\")\n",
    "    for c in cat_hint:\n",
    "        if c in df and pd.api.types.is_numeric_dtype(df[c]):\n",
    "            warn.append(f\"{c} looks numeric but expected categorical\")\n",
    "    if warn:\n",
    "        print(\"[train schema warnings]\", \"; \".join(warn))\n",
    "\n",
    "def align_for_inference(df_raw: pd.DataFrame, clf) -> pd.DataFrame:\n",
    "    df = engineer_features(df_raw.copy())\n",
    "    df = df.drop(columns=[\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\",\"Title\"], errors=\"ignore\")\n",
    "    expected = clf.named_steps[\"preprocess\"].feature_names_in_\n",
    "    # add missing / drop extras / order\n",
    "    for c in expected:\n",
    "        if c not in df.columns:\n",
    "            df[c] = pd.NA\n",
    "    df = df.loc[:, list(expected)]\n",
    "    # light dtype coercion\n",
    "    num = {'Pclass','Age','SibSp','Parch','Fare','FamilySize'}\n",
    "    cat = {'Sex','Embarked'}\n",
    "    for c in num & set(df.columns):\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    for c in cat & set(df.columns):\n",
    "        df[c] = df[c].astype(\"string\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd40db65",
   "metadata": {},
   "source": [
    "## Basic quality report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92eac669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== train dtypes ==\n",
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n",
      "\n",
      "== train missing values ==\n",
      "             n_missing        pct\n",
      "Cabin              687  77.104377\n",
      "Age                177  19.865320\n",
      "Embarked             2   0.224467\n",
      "PassengerId          0   0.000000\n",
      "Name                 0   0.000000\n",
      "Pclass               0   0.000000\n",
      "Survived             0   0.000000\n",
      "Sex                  0   0.000000\n",
      "Parch                0   0.000000\n",
      "SibSp                0   0.000000\n",
      "Fare                 0   0.000000\n",
      "Ticket               0   0.000000\n",
      "\n",
      "== train categorical cardinality ==\n",
      "Name        891\n",
      "Ticket      681\n",
      "Cabin       147\n",
      "Embarked      3\n",
      "Sex           2\n",
      "dtype: int64\n",
      "\n",
      "== test dtypes ==\n",
      "PassengerId      int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n",
      "\n",
      "== test missing values ==\n",
      "             n_missing        pct\n",
      "Cabin              327  78.229665\n",
      "Age                 86  20.574163\n",
      "Fare                 1   0.239234\n",
      "Name                 0   0.000000\n",
      "Pclass               0   0.000000\n",
      "PassengerId          0   0.000000\n",
      "Sex                  0   0.000000\n",
      "Parch                0   0.000000\n",
      "SibSp                0   0.000000\n",
      "Ticket               0   0.000000\n",
      "Embarked             0   0.000000\n",
      "\n",
      "== test categorical cardinality ==\n",
      "Name        418\n",
      "Ticket      363\n",
      "Cabin        76\n",
      "Embarked      3\n",
      "Sex           2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def quality_report(df: pd.DataFrame, label=\"df\"):\n",
    "    print(f\"\\n== {label} dtypes ==\")\n",
    "    print(df.dtypes)\n",
    "    miss = df.isna().sum().sort_values(ascending=False)\n",
    "    print(f\"\\n== {label} missing values ==\")\n",
    "    print(pd.DataFrame({\"n_missing\": miss, \"pct\": (miss/len(df))*100}).head(20))\n",
    "    print(f\"\\n== {label} categorical cardinality ==\")\n",
    "    cat_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "    card = {c: df[c].nunique(dropna=True) for c in cat_cols}\n",
    "    print(pd.Series(card).sort_values(ascending=False).head(20))\n",
    "\n",
    "quality_report(df_train, \"train\")\n",
    "if df_test is not None:\n",
    "    quality_report(df_test, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d05d2e",
   "metadata": {},
   "source": [
    "## Cleaning & typing (functions to reuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42a706bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_frame(df: pd.DataFrame, *, target: str | None = None,\n",
    "                     categorical_keep: set[str] = frozenset({\"Sex\",\"Embarked\"})) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # strip\n",
    "    obj_like = df.select_dtypes(include=[\"object\",\"string\"]).columns\n",
    "    for c in obj_like:\n",
    "        df[c] = df[c].astype(\"string\").str.strip()\n",
    "\n",
    "    # try numeric on object-like except known categoricals + target\n",
    "    try_numeric = set(obj_like) - categorical_keep - ({target} if target else set())\n",
    "    for c in try_numeric:\n",
    "        # coerce only if >90% of non-null values look numeric\n",
    "        s = df[c].dropna()\n",
    "        looks_num = s.str.fullmatch(r\"[+-]?\\d+(\\.\\d+)?\").mean() if len(s) else 0.0\n",
    "        if looks_num >= 0.9:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    # lock known categoricals\n",
    "    for c in categorical_keep & set(df.columns):\n",
    "        df[c] = df[c].astype(\"string\")\n",
    "\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "target = \"Survived\"\n",
    "df_train_clean = clean_frame(df_train, target=target)\n",
    "df_test_clean  = clean_frame(df_test,  target=target) if df_test is not None else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c5aef5",
   "metadata": {},
   "source": [
    "## Persist cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c44b6480",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_out = os.path.join(CLEAN_DIR, f\"train_clean_{ts}.csv\")\n",
    "df_train_clean.to_csv(train_out, index=False)\n",
    "\n",
    "if df_test_clean is not None:\n",
    "    test_out = os.path.join(CLEAN_DIR, f\"test_clean_{ts}.csv\")\n",
    "    df_test_clean.to_csv(test_out, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d72a54",
   "metadata": {},
   "source": [
    "## Save simple schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a73238d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved:\n",
      "../data/clean\\train_clean_20251019-211325.csv\n",
      "../data/clean\\test_clean_20251019-211325.csv\n",
      "../data/clean\\schema_20251019-211325.json\n"
     ]
    }
   ],
   "source": [
    "schema_json = os.path.join(CLEAN_DIR, f\"schema_{ts}.json\")\n",
    "schema = {c: str(t) for c, t in df_train_clean.dtypes.items()}\n",
    "with open(schema_json, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"columns\": schema, \"rows\": len(df_train_clean)}, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(train_out)\n",
    "if df_test_clean is not None: print(test_out)\n",
    "print(schema_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanic-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
